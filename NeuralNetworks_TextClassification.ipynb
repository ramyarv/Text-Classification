{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification - Call summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data of telephone conversation text and the category or purpose of the call, the problem is to classify the incoming calls based on the call data into one of those categories.\n",
    "\n",
    "Multi-class classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Flatten,Embedding,Input,Conv1D,MaxPooling1D,LSTM,SpatialDropout1D,Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "np.random.seed(1512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'backup_submissions',\n",
       " 'Batch39_Batch16_cute',\n",
       " 'best_cnn_model.h5',\n",
       " 'best_rnn_dropout_model_1.h5',\n",
       " 'best_rnn_model.h5',\n",
       " 'cnn_embed_model.csv',\n",
       " 'Cute_CS7322C_Batch16.zip',\n",
       " 'Cute_Embeddings_CNN.ipynb',\n",
       " 'Cute_Embeddings_MLP.ipynb',\n",
       " 'Cute_Embeddings_RNN.ipynb',\n",
       " 'Cute_mlp_tfidf.ipynb',\n",
       " 'description.pdf',\n",
       " 'Final_ppt_Batch16.pptx',\n",
       " 'glove.6B',\n",
       " 'glove.6B.zip',\n",
       " 'mlp_embed_model.csv',\n",
       " 'mlp_embed_model_1.csv',\n",
       " 'mlp_embed_model_2.csv',\n",
       " 'NeuralNetworks_TextClassification.ipynb',\n",
       " 'References',\n",
       " 'rnn_do_model_1.csv',\n",
       " 'rnn_do_model_2.csv',\n",
       " 'rnn_do_model_3.csv',\n",
       " 'rnn_model_1.csv',\n",
       " 'rnn_model_2.csv',\n",
       " 'samplesubmission.csv',\n",
       " 'samplesubmissionbestmlp.csv',\n",
       " 'samplesubmissiontest.csv',\n",
       " 'SampleSubmission_mlp.csv',\n",
       " 'test.csv',\n",
       " 'Text Classification of Medical Industry.ipynb',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'converse'], dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from csv input file\n",
    "inputData = pd.read_csv(\"train.csv\",index_col = \"ID\",na_values=\" \")\n",
    "inputData.columns\n",
    "\n",
    "testData = pd.read_csv(\"test.csv\",na_values=\" \")\n",
    "testData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing na values with string \"blank calls\"\n",
    "inputData = inputData.replace(np.nan,\"Blank calls\")\n",
    "testData = testData.replace(np.nan, \"Blank Calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRESCRIPTION     12077\n",
       "APPOINTMENTS     11098\n",
       "MISCELLANEOUS     9736\n",
       "ASK_A_DOCTOR      9440\n",
       "LAB               3457\n",
       "JUNK                17\n",
       "Name: categories, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData['categories'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting list of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = inputData['categories'].unique()\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words  34770\n"
     ]
    }
   ],
   "source": [
    "# tokenizer \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(inputData['converse'])\n",
    "\n",
    "word_Index = tokenizer.word_index\n",
    "vocab_size = len(word_Index)+1\n",
    "\n",
    "print(\"unique words \",vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation Split (85:15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = model_selection.train_test_split(inputData['converse'],inputData['categories'], random_state = 1512, stratify = inputData['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testData['converse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop words removal\n",
    "from nltk.corpus import stopwords\n",
    "stopwordList = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(inputList):\n",
    "   outputList = []\n",
    "   for line in inputList:\n",
    "        # tokenize line into words\n",
    "        words = word_tokenize(line)\n",
    "        # remove stop words\n",
    "        selectedWords = [word for word in words if word not in stopwordList]\n",
    "        # join back words into string (line)\n",
    "        outputLine = ' '.join(selectedWords)\n",
    "        # append back to the list to return\n",
    "        outputList.append(outputLine)\n",
    "   return outputList\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = removeStopWords(X_train)\n",
    "X_validate = removeStopWords(X_validate)\n",
    "X_test = removeStopWords(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patients running late mom appointments patient advised come office md approve mom stating mins late rna follow appointment moved phone completed appointment scheduled timephrase gina stewart rn',\n",
       " 'fyi mom patients mom several times left several messages regards appts scheduled iv drugname doctor come one appointment gas come appts also request speak nurse regarding medications need advised mom adult tonya foreman lpn patients number someone answered phone lot hollering loud talking background asked jasmine kept saying hollering continued repeatedly said one said anything hung continue try patients either phone disconnected get junk like ask nicole let know drugname go speak personally need good phone number mother must told patient patient must make phone calls phone completed denny cook rn',\n",
       " 'triage migraine request dheinj timephrase work phone patient triage adult migraines high pain level patients states bad migraine timephrase requesting inj dhe timephrase please advise timephrase rna follow patients scheduled w ginger prior authorization timephrase appointment scheduled timephrase verbalized understanding instructions joyce schwartz rn timephrase clinical list changes',\n",
       " 'several faxes requesting keppra pharmacy family pharmacy lousiburg reason call details pharmacist says sent several faxes requesting keppra none received patients almost please verbal timephrase pm cma processed Rx rf request recvd fax timephrase pm',\n",
       " 'Rx lunesa mg need insurance get paover ride prescription refill lunesta mg tabs po hs prn Rx lunesa mg need insurance get paover ride approved tabs refills insurance covers units sleep medicines including lunesta sonata patient getting sometimes per days compleed prior authorization form covermymeds faxed express scripts see attached image fax pm clinical list changes']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34368, 150)\n",
      "(11457, 150)\n"
     ]
    }
   ],
   "source": [
    "# performing padding to make all sequences of similar length \n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "\n",
    "train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen = MAX_SEQUENCE_LENGTH)\n",
    "valid_seq = pad_sequences(tokenizer.texts_to_sequences(X_validate), maxlen = MAX_SEQUENCE_LENGTH)\n",
    "test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen= MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(train_seq.shape)\n",
    "print(valid_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings - Glove 6B 100d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings - glove 6B 100d\n",
    "Embeddings_Index = {}\n",
    "for line in open('glove.6B/glove.6B.100d.txt', encoding= 'utf-8'):\n",
    "    values = line.split()\n",
    "    Embeddings_Index[values[0]] = np.asarray(values[1:],dtype='float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map words to embeddings\n",
    "embeddings_matrix = np.zeros((vocab_size,100))\n",
    "for word,i in word_Index.items():\n",
    "    vec = Embeddings_Index.get(word)\n",
    "    if vec is not None:\n",
    "        embeddings_matrix[i] = vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34770, 100)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating Embedding layer\n",
    "embeddingLayer = Embedding(vocab_size,\n",
    "                           100,\n",
    "                           weights = [embeddings_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert probabilities to categories \n",
    "def convertClassToName(test_preds):\n",
    "    y_pred = []\n",
    "    for i in test_preds:\n",
    "        num = np.argmax(i)\n",
    "        y_pred.append(categories[num])\n",
    "    return y_pred\n",
    "\n",
    "# Function to write output of model to csv file\n",
    "def writeOuputToCsv (model, filename):\n",
    "    test_preds = model.predict(test_seq)\n",
    "    y_pred = convertClassToName(test_preds)\n",
    "    data = {'ID' : testData['ID'], 'categories' : y_pred}\n",
    "    outputDf = pd.DataFrame(data= data, columns =['ID','categories'])\n",
    "    outputDf.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model (1  hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rvadamala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "inputLayer = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "embedded_sequences = embeddingLayer(inputLayer)\n",
    "dense_1 = Dense(64, activation='relu')(embedded_sequences)\n",
    "flatten = Flatten()(dense_1)\n",
    "preds = Dense(len(inputData['categories'].unique()), activation='softmax')(flatten)\n",
    "\n",
    "mlp_embed_model = Model(inputLayer,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150, 64)           6464      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 57606     \n",
      "=================================================================\n",
      "Total params: 3,541,070\n",
      "Trainable params: 64,070\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_embed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validate = encoder.fit_transform(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_validate = to_categorical(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rvadamala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2857: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\rvadamala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "mlp_embed_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/50\n",
      "34368/34368 [==============================] - 15s 438us/step - loss: 0.8546 - acc: 0.6857 - val_loss: 0.7229 - val_acc: 0.7452\n",
      "Epoch 2/50\n",
      "34368/34368 [==============================] - 16s 453us/step - loss: 0.6256 - acc: 0.7743 - val_loss: 0.7339 - val_acc: 0.7421\n",
      "Epoch 3/50\n",
      "34368/34368 [==============================] - 16s 479us/step - loss: 0.5370 - acc: 0.8044 - val_loss: 0.7494 - val_acc: 0.7437\n",
      "Epoch 4/50\n",
      "34368/34368 [==============================] - 17s 486us/step - loss: 0.4721 - acc: 0.8272 - val_loss: 0.8136 - val_acc: 0.7399\n",
      "Epoch 5/50\n",
      "34368/34368 [==============================] - 16s 480us/step - loss: 0.4190 - acc: 0.8472 - val_loss: 0.8347 - val_acc: 0.7399\n",
      "Epoch 6/50\n",
      "34368/34368 [==============================] - 16s 473us/step - loss: 0.3790 - acc: 0.8599 - val_loss: 0.8800 - val_acc: 0.7371\n",
      "Epoch 7/50\n",
      "34368/34368 [==============================] - 17s 485us/step - loss: 0.3443 - acc: 0.8752 - val_loss: 0.9514 - val_acc: 0.7356\n",
      "Epoch 8/50\n",
      "34368/34368 [==============================] - 16s 477us/step - loss: 0.3141 - acc: 0.8856 - val_loss: 1.0162 - val_acc: 0.7320\n",
      "Epoch 9/50\n",
      "34368/34368 [==============================] - 16s 471us/step - loss: 0.2894 - acc: 0.8961 - val_loss: 1.0624 - val_acc: 0.7314\n",
      "Epoch 10/50\n",
      "34368/34368 [==============================] - 16s 475us/step - loss: 0.2707 - acc: 0.9039 - val_loss: 1.1395 - val_acc: 0.7272\n",
      "Epoch 11/50\n",
      "34368/34368 [==============================] - 16s 478us/step - loss: 0.2498 - acc: 0.9098 - val_loss: 1.2100 - val_acc: 0.7268\n",
      "Epoch 12/50\n",
      "34368/34368 [==============================] - 16s 474us/step - loss: 0.2329 - acc: 0.9186 - val_loss: 1.2636 - val_acc: 0.7259\n",
      "Epoch 13/50\n",
      "34368/34368 [==============================] - 16s 468us/step - loss: 0.2207 - acc: 0.9204 - val_loss: 1.2982 - val_acc: 0.7179\n",
      "Epoch 14/50\n",
      "34368/34368 [==============================] - 16s 474us/step - loss: 0.2068 - acc: 0.9273 - val_loss: 1.3596 - val_acc: 0.7216\n",
      "Epoch 15/50\n",
      "34368/34368 [==============================] - 17s 482us/step - loss: 0.1945 - acc: 0.9310 - val_loss: 1.4179 - val_acc: 0.7190\n",
      "Epoch 16/50\n",
      "34368/34368 [==============================] - 16s 466us/step - loss: 0.1812 - acc: 0.9361 - val_loss: 1.4570 - val_acc: 0.7201\n",
      "Epoch 17/50\n",
      "34368/34368 [==============================] - 16s 460us/step - loss: 0.1739 - acc: 0.9394 - val_loss: 1.5247 - val_acc: 0.7201\n",
      "Epoch 18/50\n",
      "34368/34368 [==============================] - 17s 481us/step - loss: 0.1676 - acc: 0.9420 - val_loss: 1.5704 - val_acc: 0.7159\n",
      "Epoch 19/50\n",
      "34368/34368 [==============================] - 16s 460us/step - loss: 0.1568 - acc: 0.9456 - val_loss: 1.6186 - val_acc: 0.7219\n",
      "Epoch 20/50\n",
      "34368/34368 [==============================] - 16s 471us/step - loss: 0.1463 - acc: 0.9498 - val_loss: 1.6887 - val_acc: 0.7135\n",
      "Epoch 21/50\n",
      "34368/34368 [==============================] - 16s 455us/step - loss: 0.1413 - acc: 0.9512 - val_loss: 1.7368 - val_acc: 0.7107\n",
      "Epoch 22/50\n",
      "34368/34368 [==============================] - 16s 468us/step - loss: 0.1367 - acc: 0.9528 - val_loss: 1.7611 - val_acc: 0.7154\n",
      "Epoch 23/50\n",
      "34368/34368 [==============================] - 16s 474us/step - loss: 0.1266 - acc: 0.9570 - val_loss: 1.8314 - val_acc: 0.7117\n",
      "Epoch 24/50\n",
      "34368/34368 [==============================] - 17s 480us/step - loss: 0.1212 - acc: 0.9590 - val_loss: 1.8506 - val_acc: 0.7133\n",
      "Epoch 25/50\n",
      "34368/34368 [==============================] - 18s 534us/step - loss: 0.1169 - acc: 0.9600 - val_loss: 1.9166 - val_acc: 0.7089\n",
      "Epoch 26/50\n",
      "34368/34368 [==============================] - 18s 525us/step - loss: 0.1139 - acc: 0.9611 - val_loss: 1.9547 - val_acc: 0.7100\n",
      "Epoch 27/50\n",
      "34368/34368 [==============================] - 18s 530us/step - loss: 0.1077 - acc: 0.9639 - val_loss: 1.9874 - val_acc: 0.7138\n",
      "Epoch 28/50\n",
      "34368/34368 [==============================] - 17s 508us/step - loss: 0.1036 - acc: 0.9646 - val_loss: 2.0369 - val_acc: 0.7093\n",
      "Epoch 29/50\n",
      "34368/34368 [==============================] - 18s 534us/step - loss: 0.1016 - acc: 0.9662 - val_loss: 2.0791 - val_acc: 0.7069\n",
      "Epoch 30/50\n",
      "34368/34368 [==============================] - 19s 546us/step - loss: 0.0951 - acc: 0.9682 - val_loss: 2.0919 - val_acc: 0.7086\n",
      "Epoch 31/50\n",
      "34368/34368 [==============================] - 16s 462us/step - loss: 0.0948 - acc: 0.9683 - val_loss: 2.1358 - val_acc: 0.7071\n",
      "Epoch 32/50\n",
      "34368/34368 [==============================] - 17s 488us/step - loss: 0.0880 - acc: 0.9711 - val_loss: 2.1839 - val_acc: 0.7065\n",
      "Epoch 33/50\n",
      "34368/34368 [==============================] - 18s 517us/step - loss: 0.0850 - acc: 0.9717 - val_loss: 2.2191 - val_acc: 0.7058\n",
      "Epoch 34/50\n",
      "34368/34368 [==============================] - 17s 487us/step - loss: 0.0845 - acc: 0.9719 - val_loss: 2.2793 - val_acc: 0.7025\n",
      "Epoch 35/50\n",
      "34368/34368 [==============================] - 16s 474us/step - loss: 0.0808 - acc: 0.9729 - val_loss: 2.2892 - val_acc: 0.7054\n",
      "Epoch 36/50\n",
      "34368/34368 [==============================] - 16s 472us/step - loss: 0.0766 - acc: 0.9744 - val_loss: 2.3373 - val_acc: 0.7038\n",
      "Epoch 37/50\n",
      "34368/34368 [==============================] - 16s 477us/step - loss: 0.0780 - acc: 0.9740 - val_loss: 2.3285 - val_acc: 0.7093\n",
      "Epoch 38/50\n",
      "34368/34368 [==============================] - 16s 452us/step - loss: 0.0723 - acc: 0.9753 - val_loss: 2.3559 - val_acc: 0.7084\n",
      "Epoch 39/50\n",
      "34368/34368 [==============================] - 15s 446us/step - loss: 0.0674 - acc: 0.9777 - val_loss: 2.3757 - val_acc: 0.7056\n",
      "Epoch 40/50\n",
      "34368/34368 [==============================] - 16s 454us/step - loss: 0.0697 - acc: 0.9770 - val_loss: 2.4294 - val_acc: 0.7040\n",
      "Epoch 41/50\n",
      "34368/34368 [==============================] - 15s 448us/step - loss: 0.0683 - acc: 0.9786 - val_loss: 2.4881 - val_acc: 0.6985\n",
      "Epoch 42/50\n",
      "34368/34368 [==============================] - 16s 454us/step - loss: 0.0671 - acc: 0.9781 - val_loss: 2.4964 - val_acc: 0.7032\n",
      "Epoch 43/50\n",
      "34368/34368 [==============================] - 18s 515us/step - loss: 0.0610 - acc: 0.9796 - val_loss: 2.5180 - val_acc: 0.7046\n",
      "Epoch 44/50\n",
      "34368/34368 [==============================] - 17s 487us/step - loss: 0.0602 - acc: 0.9810 - val_loss: 2.5346 - val_acc: 0.7049\n",
      "Epoch 45/50\n",
      "34368/34368 [==============================] - 15s 446us/step - loss: 0.0621 - acc: 0.9794 - val_loss: 2.5544 - val_acc: 0.7059\n",
      "Epoch 46/50\n",
      "34368/34368 [==============================] - 16s 460us/step - loss: 0.0542 - acc: 0.9822 - val_loss: 2.5884 - val_acc: 0.7042\n",
      "Epoch 47/50\n",
      "34368/34368 [==============================] - 14s 407us/step - loss: 0.0541 - acc: 0.9823 - val_loss: 2.6168 - val_acc: 0.7011\n",
      "Epoch 48/50\n",
      "34368/34368 [==============================] - 14s 411us/step - loss: 0.0589 - acc: 0.9807 - val_loss: 2.6258 - val_acc: 0.7028\n",
      "Epoch 49/50\n",
      "34368/34368 [==============================] - 14s 414us/step - loss: 0.0548 - acc: 0.9824 - val_loss: 2.6316 - val_acc: 0.7047\n",
      "Epoch 50/50\n",
      "34368/34368 [==============================] - 15s 431us/step - loss: 0.0517 - acc: 0.9828 - val_loss: 2.6924 - val_acc: 0.7025\n"
     ]
    }
   ],
   "source": [
    "hist_mlp_embed_model = mlp_embed_model.fit(train_seq, y_train, epochs=50, validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOuputToCsv(mlp_embed_model,\"mlp_embed_model_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model - Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cnn model with embedding layer\n",
    "input_seq = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = \"int32\")\n",
    "embedding_seq = embeddingLayer(input_seq)\n",
    "x = Conv1D(64, 5, activation='relu')(embedding_seq)\n",
    "x = MaxPooling1D(4)(x)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(4)(x)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(4)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "preds = Dense(len(categories), activation='softmax')(x)\n",
    "\n",
    "cnn_embed_model = Model(input_seq,preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_embed_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 146, 64)           32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 36, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4, 64)             20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 3,554,702\n",
      "Trainable params: 77,702\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_embed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/25\n",
      "34368/34368 [==============================] - 54s 2ms/step - loss: 0.7604 - acc: 0.7220 - val_loss: 0.5925 - val_acc: 0.7844\n",
      "Epoch 2/25\n",
      "34368/34368 [==============================] - 49s 1ms/step - loss: 0.5609 - acc: 0.7968 - val_loss: 0.5662 - val_acc: 0.7921\n",
      "Epoch 3/25\n",
      "34368/34368 [==============================] - 51s 1ms/step - loss: 0.4949 - acc: 0.8166 - val_loss: 0.5684 - val_acc: 0.7912\n",
      "Epoch 4/25\n",
      "34368/34368 [==============================] - 57s 2ms/step - loss: 0.4491 - acc: 0.8355 - val_loss: 0.5817 - val_acc: 0.7880\n",
      "Epoch 5/25\n",
      "34368/34368 [==============================] - 65s 2ms/step - loss: 0.4005 - acc: 0.8534 - val_loss: 0.5872 - val_acc: 0.7877\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3),\n",
    "             ModelCheckpoint(filepath='best_cnn_model.h5', monitor='val_acc', save_best_only=True)]\n",
    "hist_cnn_embed_model = cnn_embed_model.fit(train_seq,y_train,epochs = 25,callbacks=callbacks,validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn_model = load_model('best_cnn_model.h5')\n",
    "writeOuputToCsv(best_cnn_model,\"cnn_embed_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN- LSTM Embeddings - Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple rnn with embedding layer\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(vocab_size,\n",
    "                           100,\n",
    "                           weights = [embeddings_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable = False))\n",
    "rnn_model.add(LSTM(100))\n",
    "rnn_model.add(Dense(len(categories),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,558,006\n",
      "Trainable params: 81,006\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/50\n",
      "34368/34368 [==============================] - 165s 5ms/step - loss: 0.8879 - acc: 0.6720 - val_loss: 0.6653 - val_acc: 0.7586\n",
      "Epoch 2/50\n",
      "34368/34368 [==============================] - 176s 5ms/step - loss: 0.6189 - acc: 0.7737 - val_loss: 0.5812 - val_acc: 0.7856\n",
      "Epoch 3/50\n",
      "34368/34368 [==============================] - 197s 6ms/step - loss: 0.5512 - acc: 0.7960 - val_loss: 0.5596 - val_acc: 0.7950\n",
      "Epoch 4/50\n",
      "34368/34368 [==============================] - 197s 6ms/step - loss: 0.5125 - acc: 0.8070 - val_loss: 0.5324 - val_acc: 0.7999\n",
      "Epoch 5/50\n",
      "34368/34368 [==============================] - 219s 6ms/step - loss: 0.4851 - acc: 0.8164 - val_loss: 0.5360 - val_acc: 0.7997\n",
      "Epoch 6/50\n",
      "34368/34368 [==============================] - 179s 5ms/step - loss: 0.4629 - acc: 0.8234 - val_loss: 0.5187 - val_acc: 0.8074\n",
      "Epoch 7/50\n",
      "34368/34368 [==============================] - 186s 5ms/step - loss: 0.4412 - acc: 0.8311 - val_loss: 0.5318 - val_acc: 0.7996\n",
      "Epoch 8/50\n",
      "34368/34368 [==============================] - 166s 5ms/step - loss: 0.4203 - acc: 0.8402 - val_loss: 0.5209 - val_acc: 0.8066\n",
      "Epoch 9/50\n",
      "34368/34368 [==============================] - 157s 5ms/step - loss: 0.3971 - acc: 0.8484 - val_loss: 0.5313 - val_acc: 0.8047\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3),\n",
    "             ModelCheckpoint(filepath='best_rnn_model.h5', monitor='val_acc', save_best_only=True)]\n",
    "hist_rnn_model = rnn_model.fit(train_seq,y_train,epochs = 50,callbacks= callbacks, validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn_model = load_model('best_rnn_model.h5')\n",
    "writeOuputToCsv(best_rnn_model,\"rnn_model_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN- LSTM Embeddings - Model2 ( More dense layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn including dropout\n",
    "input_seq = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = \"int32\")\n",
    "embedding_seq = embeddingLayer(input_seq)\n",
    "embedding_seq = SpatialDropout1D(0.3)(embedding_seq)\n",
    "#LSTM layer\n",
    "lstm_layer = LSTM(100)(embedding_seq)\n",
    "#dense layers\n",
    "output_layer1 = Dense(50, activation=\"relu\")(lstm_layer)\n",
    "output_layer1 = Dropout(0.25)(output_layer1)\n",
    "preds = Dense(len(categories), activation='softmax')(output_layer1)\n",
    "\n",
    "rnn_dropout_model = Model(input_seq,preds)\n",
    "rnn_dropout_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 150, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 3,562,756\n",
      "Trainable params: 85,756\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_dropout_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/50\n",
      "34368/34368 [==============================] - 162s 5ms/step - loss: 0.9526 - acc: 0.6458 - val_loss: 0.6742 - val_acc: 0.7593\n",
      "Epoch 2/50\n",
      "34368/34368 [==============================] - 159s 5ms/step - loss: 0.6799 - acc: 0.7574 - val_loss: 0.5870 - val_acc: 0.7814\n",
      "Epoch 3/50\n",
      "34368/34368 [==============================] - 157s 5ms/step - loss: 0.6134 - acc: 0.7779 - val_loss: 0.5545 - val_acc: 0.7894\n",
      "Epoch 4/50\n",
      "34368/34368 [==============================] - 159s 5ms/step - loss: 0.5756 - acc: 0.7896 - val_loss: 0.5361 - val_acc: 0.7976\n",
      "Epoch 5/50\n",
      "34368/34368 [==============================] - 163s 5ms/step - loss: 0.5532 - acc: 0.7951 - val_loss: 0.5356 - val_acc: 0.7990\n",
      "Epoch 6/50\n",
      "34368/34368 [==============================] - 162s 5ms/step - loss: 0.5390 - acc: 0.7991 - val_loss: 0.5110 - val_acc: 0.8087\n",
      "Epoch 7/50\n",
      "34368/34368 [==============================] - 163s 5ms/step - loss: 0.5189 - acc: 0.8077 - val_loss: 0.5117 - val_acc: 0.8097\n",
      "Epoch 8/50\n",
      "34368/34368 [==============================] - 172s 5ms/step - loss: 0.5032 - acc: 0.8097 - val_loss: 0.5176 - val_acc: 0.8061\n",
      "Epoch 9/50\n",
      "34368/34368 [==============================] - 200s 6ms/step - loss: 0.4905 - acc: 0.8138 - val_loss: 0.5184 - val_acc: 0.8077\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=2),\n",
    "             ModelCheckpoint(filepath='best_rnn_dropout_model_1.h5', monitor='val_acc', save_best_only=True)]\n",
    "hist_rnn_dropout_model = rnn_dropout_model.fit(train_seq,y_train,epochs = 50,callbacks= callbacks, validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn_do_model = load_model('best_rnn_dropout_model_1.h5')\n",
    "writeOuputToCsv(best_rnn_do_model,\"rnn_do_model_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
