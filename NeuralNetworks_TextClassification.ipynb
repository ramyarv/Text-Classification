{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification - Call summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data of telephone conversation text and the category or purpose of the call, the problem is to classify the incoming calls based on the call data into one of those categories.\n",
    "\n",
    "Multi-class classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rvadamala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Flatten,Embedding,Input,Conv1D,MaxPooling1D,LSTM,SpatialDropout1D,Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "np.random.seed(1512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'backup_submissions',\n",
       " 'cnn_embed_model.csv',\n",
       " 'Cute_Embeddings_CNN.ipynb',\n",
       " 'Cute_Embeddings_Final_Code.ipynb',\n",
       " 'Cute_Embeddings_MLP.ipynb',\n",
       " 'Cute_Embeddings_RNN.ipynb',\n",
       " 'Cute_mlp_tfidf.ipynb',\n",
       " 'description.pdf',\n",
       " 'glove.6B',\n",
       " 'glove.6B.zip',\n",
       " 'mlp_embed_model.csv',\n",
       " 'mlp_embed_model_1.csv',\n",
       " 'mlp_embed_model_2.csv',\n",
       " 'References',\n",
       " 'rnn_do_model_1.csv',\n",
       " 'rnn_do_model_2.csv',\n",
       " 'rnn_model_1.csv',\n",
       " 'rnn_model_2.csv',\n",
       " 'samplesubmission.csv',\n",
       " 'samplesubmissionbestmlp.csv',\n",
       " 'samplesubmissiontest.csv',\n",
       " 'SampleSubmission_mlp.csv',\n",
       " 'test.csv',\n",
       " 'train.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'converse'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pandas dataframe from csv input file\n",
    "inputData = pd.read_csv(\"train.csv\",index_col = \"ID\",na_values=\" \")\n",
    "inputData.columns\n",
    "\n",
    "testData = pd.read_csv(\"test.csv\",na_values=\" \")\n",
    "testData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing na values with string \"blank calls\"\n",
    "inputData = inputData.replace(np.nan,\"Blank calls\")\n",
    "testData = testData.replace(np.nan, \"Blank Calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRESCRIPTION     12077\n",
       "APPOINTMENTS     11098\n",
       "MISCELLANEOUS     9736\n",
       "ASK_A_DOCTOR      9440\n",
       "LAB               3457\n",
       "JUNK                17\n",
       "Name: categories, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputData['categories'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting list of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = inputData['categories'].unique()\n",
    "categories.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique words  34770\n"
     ]
    }
   ],
   "source": [
    "# tokenizer \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(inputData['converse'])\n",
    "\n",
    "word_Index = tokenizer.word_index\n",
    "vocab_size = len(word_Index)+1\n",
    "\n",
    "print(\"unique words \",vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Validation Split (85:15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validate, y_train, y_validate = model_selection.train_test_split(inputData['converse'],inputData['categories'], random_state = 1512, stratify = inputData['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testData['converse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34368, 150)\n",
      "(11457, 150)\n"
     ]
    }
   ],
   "source": [
    "# performing padding to make all sequences of similar length \n",
    "MAX_SEQUENCE_LENGTH = 150\n",
    "\n",
    "train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen = MAX_SEQUENCE_LENGTH)\n",
    "valid_seq = pad_sequences(tokenizer.texts_to_sequences(X_validate), maxlen = MAX_SEQUENCE_LENGTH)\n",
    "test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen= MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "print(train_seq.shape)\n",
    "print(valid_seq.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings - Glove 6B 100d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings - glove 6B 100d\n",
    "Embeddings_Index = {}\n",
    "for line in open('glove.6B/glove.6B.100d.txt', encoding= 'utf-8'):\n",
    "    values = line.split()\n",
    "    Embeddings_Index[values[0]] = np.asarray(values[1:],dtype='float32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map words to embeddings\n",
    "embeddings_matrix = np.zeros((vocab_size,100))\n",
    "for word,i in word_Index.items():\n",
    "    vec = Embeddings_Index.get(word)\n",
    "    if vec is not None:\n",
    "        embeddings_matrix[i] = vec\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34770, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating Embedding layer\n",
    "embeddingLayer = Embedding(vocab_size,\n",
    "                           100,\n",
    "                           weights = [embeddings_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert probabilities to categories \n",
    "def convertClassToName(test_preds):\n",
    "    y_pred = []\n",
    "    for i in test_preds:\n",
    "        num = np.argmax(i)\n",
    "        y_pred.append(categories[num])\n",
    "    return y_pred\n",
    "\n",
    "# Function to write output of model to csv file\n",
    "def writeOuputToCsv (model, filename):\n",
    "    test_preds = model.predict(test_seq)\n",
    "    y_pred = convertClassToName(test_preds)\n",
    "    data = {'ID' : testData['ID'], 'categories' : y_pred}\n",
    "    outputDf = pd.DataFrame(data= data, columns =['ID','categories'])\n",
    "    outputDf.to_csv(filename,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model (1  hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rvadamala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1255: calling reduce_prod (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "inputLayer = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "embedded_sequences = embeddingLayer(inputLayer)\n",
    "dense_1 = Dense(64, activation='relu')(embedded_sequences)\n",
    "flatten = Flatten()(dense_1)\n",
    "preds = Dense(len(inputData['categories'].unique()), activation='softmax')(flatten)\n",
    "\n",
    "mlp_embed_model = Model(inputLayer,preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150, 64)           6464      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 57606     \n",
      "=================================================================\n",
      "Total params: 3,541,070\n",
      "Trainable params: 64,070\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_embed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_validate = encoder.fit_transform(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_validate = to_categorical(y_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\rvadamala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2857: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\rvadamala\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1340: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "mlp_embed_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/50\n",
      "34368/34368 [==============================] - 17s 483us/step - loss: 0.0328 - acc: 0.9902 - val_loss: 3.0816 - val_acc: 0.6859\n",
      "Epoch 2/50\n",
      "34368/34368 [==============================] - 17s 503us/step - loss: 0.0332 - acc: 0.9896 - val_loss: 3.1015 - val_acc: 0.6846\n",
      "Epoch 3/50\n",
      "34368/34368 [==============================] - 16s 454us/step - loss: 0.0260 - acc: 0.9929 - val_loss: 3.1012 - val_acc: 0.6874\n",
      "Epoch 4/50\n",
      "34368/34368 [==============================] - 17s 494us/step - loss: 0.0267 - acc: 0.9926 - val_loss: 3.1340 - val_acc: 0.6870\n",
      "Epoch 5/50\n",
      "34368/34368 [==============================] - 17s 508us/step - loss: 0.0347 - acc: 0.9895 - val_loss: 3.1548 - val_acc: 0.6859\n",
      "Epoch 6/50\n",
      "34368/34368 [==============================] - 16s 476us/step - loss: 0.0314 - acc: 0.9900 - val_loss: 3.1882 - val_acc: 0.6854\n",
      "Epoch 7/50\n",
      "34368/34368 [==============================] - 16s 465us/step - loss: 0.0252 - acc: 0.9919 - val_loss: 3.2185 - val_acc: 0.6857\n",
      "Epoch 8/50\n",
      "34368/34368 [==============================] - 17s 494us/step - loss: 0.0294 - acc: 0.9912 - val_loss: 3.2311 - val_acc: 0.6840\n",
      "Epoch 9/50\n",
      "34368/34368 [==============================] - 16s 473us/step - loss: 0.0294 - acc: 0.9910 - val_loss: 3.1868 - val_acc: 0.6912\n",
      "Epoch 10/50\n",
      "34368/34368 [==============================] - 18s 519us/step - loss: 0.0263 - acc: 0.9919 - val_loss: 3.2408 - val_acc: 0.6857\n",
      "Epoch 11/50\n",
      "34368/34368 [==============================] - 17s 499us/step - loss: 0.0292 - acc: 0.9913 - val_loss: 3.2428 - val_acc: 0.6865\n",
      "Epoch 12/50\n",
      "34368/34368 [==============================] - 18s 522us/step - loss: 0.0289 - acc: 0.9911 - val_loss: 3.2475 - val_acc: 0.6878\n",
      "Epoch 13/50\n",
      "34368/34368 [==============================] - 16s 477us/step - loss: 0.0260 - acc: 0.9922 - val_loss: 3.2873 - val_acc: 0.6836\n",
      "Epoch 14/50\n",
      "34368/34368 [==============================] - 16s 465us/step - loss: 0.0237 - acc: 0.9936 - val_loss: 3.3105 - val_acc: 0.6855\n",
      "Epoch 15/50\n",
      "34368/34368 [==============================] - 17s 485us/step - loss: 0.0261 - acc: 0.9919 - val_loss: 3.3112 - val_acc: 0.6881\n",
      "Epoch 16/50\n",
      "34368/34368 [==============================] - 16s 476us/step - loss: 0.0215 - acc: 0.9934 - val_loss: 3.2558 - val_acc: 0.6873\n",
      "Epoch 17/50\n",
      "34368/34368 [==============================] - 16s 463us/step - loss: 0.0254 - acc: 0.9920 - val_loss: 3.3421 - val_acc: 0.6816\n",
      "Epoch 18/50\n",
      "34368/34368 [==============================] - 16s 470us/step - loss: 0.0279 - acc: 0.9916 - val_loss: 3.3859 - val_acc: 0.6827\n",
      "Epoch 19/50\n",
      "34368/34368 [==============================] - 16s 460us/step - loss: 0.0216 - acc: 0.9934 - val_loss: 3.3973 - val_acc: 0.6850\n",
      "Epoch 20/50\n",
      "34368/34368 [==============================] - 15s 438us/step - loss: 0.0277 - acc: 0.9913 - val_loss: 3.4028 - val_acc: 0.6843\n",
      "Epoch 21/50\n",
      "34368/34368 [==============================] - 15s 447us/step - loss: 0.0261 - acc: 0.9919 - val_loss: 3.4258 - val_acc: 0.6820\n",
      "Epoch 22/50\n",
      "34368/34368 [==============================] - 15s 431us/step - loss: 0.0206 - acc: 0.9938 - val_loss: 3.4609 - val_acc: 0.6808\n",
      "Epoch 23/50\n",
      "34368/34368 [==============================] - 15s 436us/step - loss: 0.0179 - acc: 0.9948 - val_loss: 3.4209 - val_acc: 0.6826\n",
      "Epoch 24/50\n",
      "34368/34368 [==============================] - 14s 421us/step - loss: 0.0211 - acc: 0.9939 - val_loss: 3.4468 - val_acc: 0.6863\n",
      "Epoch 25/50\n",
      "34368/34368 [==============================] - 16s 471us/step - loss: 0.0270 - acc: 0.9919 - val_loss: 3.4492 - val_acc: 0.6823\n",
      "Epoch 26/50\n",
      "34368/34368 [==============================] - 15s 435us/step - loss: 0.0297 - acc: 0.9904 - val_loss: 3.4465 - val_acc: 0.6840\n",
      "Epoch 27/50\n",
      "34368/34368 [==============================] - 15s 449us/step - loss: 0.0195 - acc: 0.9941 - val_loss: 3.5082 - val_acc: 0.6799\n",
      "Epoch 28/50\n",
      "34368/34368 [==============================] - 15s 436us/step - loss: 0.0205 - acc: 0.9937 - val_loss: 3.4739 - val_acc: 0.6841\n",
      "Epoch 29/50\n",
      "34368/34368 [==============================] - 16s 461us/step - loss: 0.0209 - acc: 0.9935 - val_loss: 3.4921 - val_acc: 0.6840\n",
      "Epoch 30/50\n",
      "34368/34368 [==============================] - 15s 422us/step - loss: 0.0273 - acc: 0.9911 - val_loss: 3.4891 - val_acc: 0.6826\n",
      "Epoch 31/50\n",
      "34368/34368 [==============================] - 16s 480us/step - loss: 0.0222 - acc: 0.9932 - val_loss: 3.5245 - val_acc: 0.6830\n",
      "Epoch 32/50\n",
      "34368/34368 [==============================] - 18s 528us/step - loss: 0.0226 - acc: 0.9932 - val_loss: 3.5184 - val_acc: 0.6833\n",
      "Epoch 33/50\n",
      "34368/34368 [==============================] - 16s 479us/step - loss: 0.0205 - acc: 0.9934 - val_loss: 3.5226 - val_acc: 0.6846\n",
      "Epoch 34/50\n",
      "34368/34368 [==============================] - 15s 428us/step - loss: 0.0198 - acc: 0.9945 - val_loss: 3.5189 - val_acc: 0.6856\n",
      "Epoch 35/50\n",
      "34368/34368 [==============================] - 14s 420us/step - loss: 0.0219 - acc: 0.9936 - val_loss: 3.5052 - val_acc: 0.6858\n",
      "Epoch 36/50\n",
      "34368/34368 [==============================] - 14s 419us/step - loss: 0.0243 - acc: 0.9923 - val_loss: 3.4989 - val_acc: 0.6894\n",
      "Epoch 37/50\n",
      "34368/34368 [==============================] - 14s 421us/step - loss: 0.0192 - acc: 0.9939 - val_loss: 3.5428 - val_acc: 0.6809\n",
      "Epoch 38/50\n",
      "34368/34368 [==============================] - 14s 407us/step - loss: 0.0196 - acc: 0.9936 - val_loss: 3.5176 - val_acc: 0.6855\n",
      "Epoch 39/50\n",
      "34368/34368 [==============================] - 17s 486us/step - loss: 0.0214 - acc: 0.9941 - val_loss: 3.5511 - val_acc: 0.6816\n",
      "Epoch 40/50\n",
      "34368/34368 [==============================] - 16s 477us/step - loss: 0.0186 - acc: 0.9945 - val_loss: 3.5582 - val_acc: 0.6847\n",
      "Epoch 41/50\n",
      "34368/34368 [==============================] - 15s 430us/step - loss: 0.0228 - acc: 0.9932 - val_loss: 3.5659 - val_acc: 0.6856\n",
      "Epoch 42/50\n",
      "34368/34368 [==============================] - 14s 403us/step - loss: 0.0237 - acc: 0.9930 - val_loss: 3.5920 - val_acc: 0.6861\n",
      "Epoch 43/50\n",
      "34368/34368 [==============================] - 13s 392us/step - loss: 0.0228 - acc: 0.9933 - val_loss: 3.6303 - val_acc: 0.6819\n",
      "Epoch 44/50\n",
      "34368/34368 [==============================] - 13s 391us/step - loss: 0.0256 - acc: 0.9925 - val_loss: 3.5796 - val_acc: 0.6874\n",
      "Epoch 45/50\n",
      "34368/34368 [==============================] - 14s 402us/step - loss: 0.0189 - acc: 0.9949 - val_loss: 3.6079 - val_acc: 0.6831\n",
      "Epoch 46/50\n",
      "34368/34368 [==============================] - 14s 395us/step - loss: 0.0145 - acc: 0.9964 - val_loss: 3.6960 - val_acc: 0.6781\n",
      "Epoch 47/50\n",
      "34368/34368 [==============================] - 14s 396us/step - loss: 0.0269 - acc: 0.9917 - val_loss: 3.6205 - val_acc: 0.6838\n",
      "Epoch 48/50\n",
      "34368/34368 [==============================] - 14s 400us/step - loss: 0.0204 - acc: 0.9938 - val_loss: 3.6580 - val_acc: 0.6833\n",
      "Epoch 49/50\n",
      "34368/34368 [==============================] - 14s 409us/step - loss: 0.0191 - acc: 0.9941 - val_loss: 3.6668 - val_acc: 0.6820\n",
      "Epoch 50/50\n",
      "34368/34368 [==============================] - 18s 523us/step - loss: 0.0255 - acc: 0.9924 - val_loss: 3.6513 - val_acc: 0.6846\n"
     ]
    }
   ],
   "source": [
    "hist_mlp_embed_model = mlp_embed_model.fit(train_seq, y_train, epochs=50, validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "writeOuputToCsv(mlp_embed_model,\"mlp_embed_model_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model - Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cnn model with embedding layer\n",
    "input_seq = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = \"int32\")\n",
    "embedding_seq = embeddingLayer(input_seq)\n",
    "x = Conv1D(64, 5, activation='relu')(embedding_seq)\n",
    "x = MaxPooling1D(4)(x)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(4)(x)\n",
    "x = Conv1D(64, 5, activation='relu')(x)\n",
    "x = MaxPooling1D(4)(x)  # global max pooling\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "preds = Dense(len(categories), activation='softmax')(x)\n",
    "\n",
    "cnn_embed_model = Model(input_seq,preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_embed_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 146, 64)           32064     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 36, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 4, 64)             20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 3,554,702\n",
      "Trainable params: 77,702\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_embed_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/25\n",
      "34368/34368 [==============================] - 59s 2ms/step - loss: 0.8045 - acc: 0.7022 - val_loss: 0.6555 - val_acc: 0.7659\n",
      "Epoch 2/25\n",
      "34368/34368 [==============================] - 54s 2ms/step - loss: 0.5955 - acc: 0.7833 - val_loss: 0.6216 - val_acc: 0.7740\n",
      "Epoch 3/25\n",
      "34368/34368 [==============================] - 55s 2ms/step - loss: 0.5338 - acc: 0.8033 - val_loss: 0.5838 - val_acc: 0.7870\n",
      "Epoch 4/25\n",
      "34368/34368 [==============================] - 59s 2ms/step - loss: 0.4796 - acc: 0.8208 - val_loss: 0.6336 - val_acc: 0.7792\n",
      "Epoch 5/25\n",
      "34368/34368 [==============================] - 65s 2ms/step - loss: 0.4317 - acc: 0.8390 - val_loss: 0.6019 - val_acc: 0.7872\n",
      "Epoch 6/25\n",
      "34368/34368 [==============================] - 60s 2ms/step - loss: 0.3832 - acc: 0.8545 - val_loss: 0.6484 - val_acc: 0.7780\n",
      "Epoch 7/25\n",
      "34368/34368 [==============================] - 56s 2ms/step - loss: 0.3334 - acc: 0.8733 - val_loss: 0.7196 - val_acc: 0.7699\n",
      "Epoch 8/25\n",
      "34368/34368 [==============================] - 60s 2ms/step - loss: 0.2822 - acc: 0.8948 - val_loss: 0.7660 - val_acc: 0.7638\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3),\n",
    "             ModelCheckpoint(filepath='best_cnn_model.h5', monitor='val_acc', save_best_only=True)]\n",
    "hist_cnn_embed_model = cnn_embed_model.fit(train_seq,y_train,epochs = 25,callbacks=callbacks,validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cnn_model = load_model('best_cnn_model.h5')\n",
    "writeOuputToCsv(best_cnn_model,\"cnn_embed_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN- LSTM Embeddings - Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple rnn with embedding layer\n",
    "rnn_model = Sequential()\n",
    "rnn_model.add(Embedding(vocab_size,\n",
    "                           100,\n",
    "                           weights = [embeddings_matrix],\n",
    "                           input_length = MAX_SEQUENCE_LENGTH,\n",
    "                           trainable = False))\n",
    "rnn_model.add(LSTM(100))\n",
    "rnn_model.add(Dense(len(categories),activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 3,558,006\n",
      "Trainable params: 81,006\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/50\n",
      "34368/34368 [==============================] - 198s 6ms/step - loss: 0.9518 - acc: 0.6445 - val_loss: 0.7255 - val_acc: 0.7426\n",
      "Epoch 2/50\n",
      "34368/34368 [==============================] - 165s 5ms/step - loss: 0.6616 - acc: 0.7599 - val_loss: 0.6142 - val_acc: 0.7789\n",
      "Epoch 3/50\n",
      "34368/34368 [==============================] - 157s 5ms/step - loss: 0.5827 - acc: 0.7858 - val_loss: 0.5755 - val_acc: 0.7850\n",
      "Epoch 4/50\n",
      "34368/34368 [==============================] - 180s 5ms/step - loss: 0.5393 - acc: 0.7996 - val_loss: 0.5649 - val_acc: 0.7879\n",
      "Epoch 5/50\n",
      "34368/34368 [==============================] - 156s 5ms/step - loss: 0.5129 - acc: 0.8052 - val_loss: 0.5544 - val_acc: 0.7925\n",
      "Epoch 6/50\n",
      "34368/34368 [==============================] - 167s 5ms/step - loss: 0.4884 - acc: 0.8137 - val_loss: 0.5438 - val_acc: 0.7940\n",
      "Epoch 7/50\n",
      "34368/34368 [==============================] - 156s 5ms/step - loss: 0.4668 - acc: 0.8216 - val_loss: 0.5457 - val_acc: 0.7955\n",
      "Epoch 8/50\n",
      "34368/34368 [==============================] - 150s 4ms/step - loss: 0.4448 - acc: 0.8298 - val_loss: 0.5470 - val_acc: 0.7961\n",
      "Epoch 9/50\n",
      "34368/34368 [==============================] - 146s 4ms/step - loss: 0.4189 - acc: 0.8403 - val_loss: 0.5655 - val_acc: 0.7950\n",
      "Epoch 10/50\n",
      "34368/34368 [==============================] - 173s 5ms/step - loss: 0.3972 - acc: 0.8454 - val_loss: 0.5864 - val_acc: 0.7953\n",
      "Epoch 11/50\n",
      "34368/34368 [==============================] - 166s 5ms/step - loss: 0.3726 - acc: 0.8566 - val_loss: 0.5839 - val_acc: 0.7920\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=3),\n",
    "             ModelCheckpoint(filepath='best_rnn_model.h5', monitor='val_acc', save_best_only=True)]\n",
    "hist_rnn_model = rnn_model.fit(train_seq,y_train,epochs = 50,callbacks= callbacks, validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn_model = load_model('best_rnn_model.h5')\n",
    "writeOuputToCsv(best_rnn_model,\"rnn_model_2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN- LSTM Embeddings - Model2 ( More dense layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rnn including dropout\n",
    "input_seq = Input(shape = (MAX_SEQUENCE_LENGTH,), dtype = \"int32\")\n",
    "embedding_seq = embeddingLayer(input_seq)\n",
    "embedding_seq = SpatialDropout1D(0.3)(embedding_seq)\n",
    "#LSTM layer\n",
    "lstm_layer = LSTM(100)(embedding_seq)\n",
    "#dense layers\n",
    "output_layer1 = Dense(50, activation=\"relu\")(lstm_layer)\n",
    "output_layer1 = Dropout(0.25)(output_layer1)\n",
    "preds = Dense(len(categories), activation='softmax')(output_layer1)\n",
    "\n",
    "rnn_dropout_model = Model(input_seq,preds)\n",
    "rnn_dropout_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 150, 100)          3477000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 150, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 3,562,756\n",
      "Trainable params: 85,756\n",
      "Non-trainable params: 3,477,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn_dropout_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34368 samples, validate on 11457 samples\n",
      "Epoch 1/50\n",
      "34368/34368 [==============================] - 171s 5ms/step - loss: 1.0338 - acc: 0.6079 - val_loss: 0.7086 - val_acc: 0.7383\n",
      "Epoch 2/50\n",
      "34368/34368 [==============================] - 185s 5ms/step - loss: 0.7266 - acc: 0.7402 - val_loss: 0.6352 - val_acc: 0.7673\n",
      "Epoch 3/50\n",
      "34368/34368 [==============================] - 150s 4ms/step - loss: 0.6647 - acc: 0.7589 - val_loss: 0.5996 - val_acc: 0.7787\n",
      "Epoch 4/50\n",
      "34368/34368 [==============================] - 151s 4ms/step - loss: 0.6239 - acc: 0.7730 - val_loss: 0.5805 - val_acc: 0.7841\n",
      "Epoch 5/50\n",
      "34368/34368 [==============================] - 152s 4ms/step - loss: 0.5960 - acc: 0.7810 - val_loss: 0.5622 - val_acc: 0.7865\n",
      "Epoch 6/50\n",
      "34368/34368 [==============================] - 146s 4ms/step - loss: 0.5750 - acc: 0.7876 - val_loss: 0.5589 - val_acc: 0.7899\n",
      "Epoch 7/50\n",
      "34368/34368 [==============================] - 147s 4ms/step - loss: 0.5613 - acc: 0.7897 - val_loss: 0.5402 - val_acc: 0.7978\n",
      "Epoch 8/50\n",
      "34368/34368 [==============================] - 150s 4ms/step - loss: 0.5416 - acc: 0.7976 - val_loss: 0.5435 - val_acc: 0.7997\n",
      "Epoch 9/50\n",
      "34368/34368 [==============================] - 149s 4ms/step - loss: 0.5288 - acc: 0.8027 - val_loss: 0.5430 - val_acc: 0.7976\n",
      "Epoch 10/50\n",
      "34368/34368 [==============================] - 150s 4ms/step - loss: 0.5176 - acc: 0.8038 - val_loss: 0.5525 - val_acc: 0.7955\n"
     ]
    }
   ],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_acc', patience=2),\n",
    "             ModelCheckpoint(filepath='best_rnn_dropout_model_1.h5', monitor='val_acc', save_best_only=True)]\n",
    "hist_rnn_dropout_model = rnn_dropout_model.fit(train_seq,y_train,epochs = 50,callbacks= callbacks, validation_data=(valid_seq,y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rnn_do_model = load_model('best_rnn_dropout_model_1.h5')\n",
    "writeOuputToCsv(best_rnn_do_model,\"rnn_do_model_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
